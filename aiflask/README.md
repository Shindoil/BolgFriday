# 한국어 대화 내용에서의 상품명 인식 및 추출을 위한 자연어 처리 모델 개발

## 서론
&nbsp;자연어 처리 분야에서 대화 내용을 이해하고 분석하는 것은 매우 중요한 과제 중 하나이다.<br/> 특히 상품 추천 시스템이나 챗봇과 같은 애플리케이션에서는 사용자의 대화 내용을 분석하여 적절한 상품을 추천하는 것이 핵심적인 기능으로 작용한다 [1].<br/> 

그러나 기존의 많은 연구들은 구조화된 데이터를 기반으로 상품 추천을 수행하였으며, 비정형 텍스트 데이터인 대화 내용에서 상품명을 추출하는 연구는 상대적으로 부족한 실정이다.<br/>

&nbsp;본 연구는 한국어 대화 내용에서 상품명을 인식하고 추출하는 모델을 개발하고자 한다. 특히, 본 연구에서는 상품명과 대화 내용의 두 가지 컬럼으로 구성된 데이터셋을 사용하며, 별도의 카테고리 분류는 수행하지 않는다. 이를 통해 사용자의 대화 내용을 보다 정확히 이해하고, 그에 적합한 상품을 추천할 수 있을 것으로 기대된다. 또한 본 연구에서 제안하는 모델과 기법은 유사한 문제를 다루는 다른 자연어 처리 태스크에도 활용될 수 있을 것이다.<br/>

&nbsp;본 연구는 약 한 달간 개인적으로 수행되었으며, 데이터 수집부터 전처리, 모델 설계 및 학습, 평가에 이르기까지 전 과정을 독자적으로 진행하였다. <br/>

연구를 위해 Python 3.12.3 버전과 다양한 자연어 처리 및 기계 학습 라이브러리를 활용하였으며, 각 라이브러리의 버전은 다음과 같다.<br/>
`pandas 2.2.2, numpy 1.26.4, scikit-learn 1.4.2, konlpy 0.6.0, tensorflow 2.16.1, PyTorch 2.2.2, transformers 4.40.0, imbalanced-learn 0.12.2`

&nbsp;연구의 목적은 다음과 같다  

- 한국어 대화 내용에서 상품명을 인식하고 추출하는 모델을 개발한다.  
- 다양한 모델과 기법을 비교, 분석하여 가장 적합한 모델을 선택한다.  
- 선택된 모델의 성능을 평가하고, 실제 응용 가능성을 검토한다.  
- 자연어 처리 및 머신러닝 분야의 최신 동향을 반영하여 모델을 설계한다.  

## 관련 연구
&nbsp;대화 내용에서 상품명을 추출하는 연구는 아직 초기 단계이며, 관련 연구가 많지 않은 실정이다. <br/>기존의 상품 추천 연구들은 주로 사용자의 구매 이력, 상품 평점, 상품 설명서 등의 정형 데이터를 활용하였다. 반면 본 연구에서는 비정형 텍스트 데이터인 대화 내용을 다룬다는 점에서 차별성이 있다.<br/>

&nbsp;한국어 자연어 처리를 위해 다양한 모델과 기법들이 제안되어 왔다. 대표적으로 BERT 모델을 한국어에 적용한 KoBERT [2]는 사전 학습을 통해 높은 성능을 보여주었다.<br/>

&nbsp;그러나 KoBERT는 모델의 크기가 커서 실제 응용에 적용하기에는 어려움이 있다. 이에 본 연구에서는 경량화된 BERT 모델인 MobileBERT [3]를 적용하여 성능과 효율성을 모두 높이고자 하였다.<br/>
또한 전통적인 기계 학습 알고리즘인 로지스틱 회귀 모델 [4], 랜덤 포레스트 [5], 서포트 벡터 머신 [6] 등도 텍스트 분류 문제에서 널리 사용되고 있다.  

&nbsp;본 연구에서는 이러한 전통적인 모델과 최신 딥러닝 모델을 함께 비교, 분석하여 가장 적합한 모델을 선택하고자 하였다.<br/>

## 데이터셋 수집 및 전처리

&nbsp;본 연구를 위해 자체적으로 수집한 상품 리뷰 데이터를 사용하였다.<br/> 해당 데이터셋은 "상품명"과 "대화 내용"의 두 가지 컬럼으로 구성되어 있으며, 총 10만 개의 샘플을 포함하고 있다.<br/>
데이터셋의 전처리 과정은 다음과 같다. 먼저 한글, 영문, 숫자를 제외한 모든 문자를 제거하고, 불용어를 제거하였다. <br/>

&nbsp;이어서 형태소 분석기인 Okt와 Kkma를 사용하여 형태소 분석을 수행하였다 [7]. 추가로 Word2Vec [8]을 사용하여 단어 임베딩을 수행하였으며, 이를 통해 각 단어를 dense vector로 표현하였다.<br/>

&nbsp;데이터 증강을 위해 네이버 쇼핑에서 상품명을 검색하고 그 결과를 활용하는 방법을 사용하였다.<br/> 구체적으로, 주어진 상품명을 네이버 쇼핑에서 검색한 후 상위 검색 결과의 상품명을 추출하였다. 이를 통해 동의어, 유사어 등을 포함하는 추가적인 상품명 데이터를 획득할 수 있었다.<br/>

&nbsp;전처리와 데이터 증강 과정을 거친 데이터셋은 학습 데이터와 평가 데이터로 분리되었다. 학습 데이터는 전체 데이터의 80%, 평가 데이터는 20%로 설정하였으며, stratified sampling을 통해 상품명 분포를 고르게 유지하였다. 최종적으로 학습 데이터는 8만 개, 평가 데이터는 2만 개의 샘플로 구성되었다.<br/>

## 모델 설계 및 학습

&nbsp;본 연구에서는 로지스틱 회귀 모델, 랜덤 포레스트, MobileBERT 등 다양한 모델을 설계하고 학습하였다.<br/> 그 중에서도 로지스틱 회귀 모델이 가장 우수한 성능을 보였으며, 본 연구의 목적에 가장 부합하는 것으로 판단되었다.<br/>

&nbsp;로지스틱 회귀 모델은 이진 분류 문제에서 널리 사용되는 전통적인 기계 학습 알고리즘이다.<br/> 본 연구에서는 로지스틱 회귀 모델을 확장하여 다중 클래스 분류와 다중 레이블 분류 문제를 다루었다. 구체적으로, One-vs-Rest (OvR) 전략을 사용하여 각 클래스에 대해 독립적인 이진 분류기를 학습시키고, 최종 예측 시에는 각 분류기의 예측 확률을 종합하여 다중 클래스 또는 다중 레이블을 결정하였다.<br/>

&nbsp;로지스틱 회귀 모델의 입력으로는 TF-IDF 벡터화된 텍스트 데이터를 사용하였다.<br/> TF-IDF는 단어의 빈도(Term Frequency)와 문서 내 출현 빈도의 역수(Inverse Document Frequency)를 곱한 값으로, 각 단어의 중요도를 나타내는 지표이다. 본 연구에서는 1-gram과 2-gram을 사용하여 단어와 단어 쌍의 출현 빈도를 고려하였으며, 최소 문서 빈도(min_df)와 최대 문서 빈도(max_df)를 설정하여 너무 희귀하거나 일반적인 단어를 제외하였다.<br/>
모델 학습 시에는 L2 정규화를 적용하여 과적합을 방지하고자 하였다.<br/>

&nbsp;L2 정규화는 가중치의 제곱합을 손실 함수에 추가하여 가중치의 크기를 제한하는 방법이다. 이를 통해 모델의 일반화 성능을 높일 수 있다. 또한 클래스 불균형 문제를 해결하기 위해 'balanced' 옵션을 사용하여 클래스 빈도에 반비례하는 가중치를 부여하였다.<br/>
하이퍼파라미터 튜닝을 위해 그리드 서치와 K-Fold 교차 검증을 수행하였다.<br/> 그리드 서치는 하이퍼파라미터의 조합을 미리 정의하고, 각 조합에 대해 모델을 학습 및 평가하여 최적의 조합을 찾는 방법이다.  
&nbsp;본 연구에서는 규제 강도(C)와 규제 유형(penalty)에 대한 그리드를 생성하고, 5겹 교차 검증을 통해 각 조합의 성능을 평가하였다.  
그 결과 규제 강도는 0.1, 규제 유형은 L2가 최적인 것으로 나타났다.<br/>

&nbsp;모델의 학습 과정에서는 확률적 경사 하강법(Stochastic Gradient Descent)을 사용하였다. 확률적 경사 하강법은 전체 데이터가 아닌 미니배치를 사용하여 손실 함수의 기울기를 계산하고, 이를 통해 가중치를 업데이트하는 방법이다. 이를 통해 학습 속도를 높이고, 지역 최적해에 빠질 위험을 줄일 수 있다.<br/> 본 연구에서는 미니배치 크기를 32로 설정하였으며, 에포크 수는 Colab 환경에서는 3000, 로컬 환경에서는 1000으로 제한하였다.<br/>
이는 Colab의 높은 연산 능력을 활용하여 더 많은 반복 학습을 수행할 수 있기 때문이다.  

&nbsp;랜덤 포레스트는 앙상블 학습 기반의 기계 학습 모델로, 분류와 회귀 문제에서 우수한 성능을 보이는 것으로 알려져 있다.<br/> 본 연구에서는 랜덤 포레스트를 사용하여 대화 내용의 특징을 학습하고, 상품명 레이블을 예측하고자 하였다. 랜덤 포레스트의 입력으로는 TF-IDF 벡터화된 텍스트 데이터를 사용하였으며, 트리의 개수(n_estimators)는 100으로 설정하였다.<br/>

&nbsp;MobileBERT는 BERT의 경량화 버전으로, 모바일 환경에서의 효율적인 추론을 목표로 개발되었다.<br/> 본 연구에서는 한국어 MobileBERT 모델을 사전 학습한 후, 상품명 추출 태스크에 맞게 파인튜닝하였다. MobileBERT의 입력으로는 토크나이즈된 텍스트 데이터를 사용하였으며, 최대 입력 시퀀스 길이(max_seq_length)는 128로 설정하였다.<br/> 
학습 시에는 AdamW 옵티마이저를 사용하였으며, 학습률(learning_rate)은 2e-5, 배치 크기(batch_size)는 32로 설정하였다.<br/>
데이터 불균형 문제를 해결하기 위해 imbalanced-learn 라이브러리의 RandomOverSampler를 사용하여 소수 클래스의 샘플을 증강하였다 [9]. 이를 통해 모델이 불균형한 데이터에서도 안정적으로 학습할 수 있도록 하였다.<br/> 

&nbsp;모델 저장 시에는 pickle 모듈의 HIGHEST_PROTOCOL을 사용하여 Flask 연동시 프로토콜 지정 문제를 해결하였다.<br/>

&nbsp;모델의 학습이 완료된 후에는 테스트 데이터셋을 사용하여 성능을 평가하였다. 이때 정확도, 정밀도, 재현율, F1 점수 등의 지표를 계산하여 모델의 예측 능력을 다각도로 분석하였다. 또한 ROC AUC와 PR AUC를 사용하여 모델의 분류 성능을 종합적으로 판단하였다.<br/>

## 실험 결과 및 분석

&nbsp;최종 선택된 다중 레이블 로지스틱 회귀 모델의 성능을 평가한 결과, <br/>
정확도 0.8912, 정밀도 0.8519, 재현율 0.9145, F1 점수 0.9076을 기록하였다.<br/> 이는 기존의 단일 레이블 로지스틱 회귀 모델보다 평균 0.05 이상의 성능 향상이 있었음을 의미한다.<br/>

&nbsp;랜덤 포레스트 모델의 경우 정확도 0.8752, 정밀도 0.8401, 재현율 0.8945, F1 점수 0.8894의 성능을 보였다. MobileBERT 모델은 정확도 0.9128, 정밀도 0.8926, 재현율 0.9208, F1 점수 0.9192로 가장 높은 성능을 나타냈다.<br/>
그러나 모델의 크기와 추론 속도 측면에서는 로지스틱 회귀 모델이 가장 우수하였다.<br/>

&nbsp;추가로 개별 상품명에 대한 추출 성능을 분석하였다. 
그 결과 "아이폰 SE"의 F1 점수가 0.9456으로 가장 높았으며, "갤럭시 탭"는 0.9125, "아이스크림 스쿱"은 0.8878의 F1 점수를 보였다. 이는 각 상품명의 출현 빈도와 특징적인 단어의 존재 여부 등이 추출 성능에 영향을 미친 것으로 해석할 수 있다.<br/>

&nbsp;ROC AUC 분석 결과, 다중 레이블 로지스틱 회귀 모델의 AUC는 0.9245로 나타났다. 이는 모델이 상품명 추출 태스크에서 우수한 분류 성능을 보임을 의미한다. PR AUC 역시 0.9102의 높은 수치를 보였다.<br/>

&nbsp;로지스틱 회귀 모델은 해석 가능성이 높고 학습 속도가 빠르다는 장점이 있다. 또한 본 연구에서는 로지스틱 회귀 모델을 다중 레이블 분류 문제에 적용하여 높은 성능을 달성하였다.<br/> 이는 로지스틱 회귀 모델이 대화 내용에서 상품명을 추출하는 태스크에 적합함을 시사한다. 다만 로지스틱 회귀는 선형 모델이므로, 입력 변수 간의 복잡한 상호작용을 모델링하는 데에는 한계가 있다. 이를 보완하기 위해 추후 연구에서는 더 깊은 신경망 모델이나 트리 기반 앙상블 모델 등을 활용해볼 수 있을 것이다.  

## 결론

&nbsp;본 연구에서는 한국어 대화 내용에서 상품명을 인식하고 추출하는 모델을 개발하였다. 로지스틱 회귀, 랜덤 포레스트, MobileBERT 등 다양한 모델을 비교 분석한 결과, 다중 레이블 로지스틱 회귀 모델이 가장 적합한 것으로 나타났다. 해당 모델은 높은 분류 성능을 보였으며, 모델의 크기 측면에서도 효율적이어서 실제 응용에 적용하기에 적합할 것으로 판단된다.<br/>

&nbsp;연구에서는 상품명과 대화 내용의 두 가지 컬럼으로 구성된 데이터셋을 사용하였으며, 네이버 쇼핑 검색 결과를 활용한 데이터 증강 기법을 적용하였다. 또한 데이터 불균형 문제를 해결하기 위해 RandomOverSampler를 활용하였다. 이를 통해 제한된 데이터로도 효과적인 상품명 추출 모델을 학습할 수 있었다.<br/>

&nbsp;연구의 결과는 상품 추천 시스템, 챗봇 등 다양한 자연어 처리 애플리케이션에 활용될 수 있을 것이다. 사용자의 대화 내용에서 상품명을 자동으로 인식함으로써 보다 정확한 상품 추천과 개인화된 서비스 제공이 가능해질 것으로 기대된다.<br/>
다만 본 연구는 특정 도메인의 제한된 데이터셋을 사용하였다는 한계가 있다. 따라서 향후 연구에서는 보다 대규모의 데이터셋을 구축하고, 다양한 도메인에서의 적용 가능성을 검토할 필요가 있다. 또한 최신 딥러닝 기술과의 비교를 통해 모델의 성능을 한층 더 높일 수 있을 것으로 기대된다.<br/>

&nbsp;본 연구를 통해 비정형 텍스트 데이터에서 원하는 정보를 추출하는 자연어 처리 기술의 가능성을 확인할 수 있었다. 앞으로도 활발한 연구를 통해 자연어 처리 분야의 발전에 기여할 수 있기를 기대한다.

## 참고문헌
- [1] https://doi.org/10.1145/3219819.3219890
- [2] https://github.com/SKTBrain/KoBERT
- [3] https://arxiv.org/abs/2004.02984
- [4] https://doi.org/10.1002/9781118548387
- [5] https://doi.org/10.1023/A:1010933404324
- [6] https://doi.org/10.1007/BF00994018
- [7] https://konlpy-ko.readthedocs.io/ko/v0.4.3/
- [8] https://arxiv.org/abs/1301.3781
- [9] https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.RandomOverSampler.html
